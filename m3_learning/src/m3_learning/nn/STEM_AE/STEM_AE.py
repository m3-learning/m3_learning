import torch
import torch.nn as nn
import torch.optim as optim
from os.path import join as pjoin
from torch.utils.data import Dataset, DataLoader
from ..Regularization.Regularizers import ContrastiveLoss, DivergenceLoss
from tqdm import tqdm
from m3_learning.util.file_IO import make_folder
import torch.nn.functional as F
from torch.autograd import Variable
import numpy as np
import glob
import h5py

class ConvAutoencoder():
    """builds the convolutional autoencoder
    """

    def __init__(self,
                 encoder_step_size,
                 pooling_list,
                 decoder_step_size,
                 upsampling_list,
                 embedding_size,
                 conv_size,
                 device,
                 learning_rate=3e-5,
                 ):
        """Initialization function

        Args:
            encoder_step_size (list): sets the size of the encoder
            pooling_list (list): sets the pooling list to define the pooling layers
            decoder_step_size (list): sets the size of the decoder
            upsampling_list (list): sets the size for upsampling
            embedding_size (int): number of embedding channels
            conv_size (int): sets the number of convolutional neurons in the model
            device (torch.device): set the device to run the model
            learning_rate (float, optional): sets the learning rate for the optimizer. Defaults to 3e-5.
        """
        self.encoder_step_size = encoder_step_size
        self.pooling_list = pooling_list
        self.decoder_step_size = decoder_step_size
        self.upsampling_list = upsampling_list
        self.embedding_size = embedding_size
        self.conv_size = conv_size
        self.device = device
        self.learning_rate = learning_rate

        # complies the network
        self.compile_model()

    def compile_model(self,beta=0):
        """function that complies the neural network model
        """

        # builds the encoder
        self.encoder = Encoder(
            original_step_size=self.encoder_step_size,
            pooling_list=self.pooling_list,
            embedding_size=self.embedding_size,
            conv_size=self.conv_size,
        ).to(self.device)

        # builds the decoder
        self.decoder = Decoder(
            original_step_size=self.decoder_step_size,
            upsampling_list=self.upsampling_list,
            embedding_size=self.embedding_size,
            conv_size=self.conv_size,
            pooling_list=self.pooling_list,
        ).to(self.device)

        # builds the autoencoder
        self.autoencoder = AutoEncoder(
            self.encoder, self.decoder).to(self.device)

        # sets the optimizers
        self.optimizer = optim.Adam(
            self.autoencoder.parameters(), lr=self.learning_rate
        )

        # sets the datatype of the model to float32
        self.autoencoder.type(torch.float32)

    def Train(self,
              data,
              max_learning_rate=1e-4,
              coef_1=0,
              coef_2=0,
              coef_3=0,
              seed=12,
              epochs=100,
              with_scheduler=True,
              ln_parm=1,
              epoch_=None,
              folder_path='./',
              batch_size=32,
              best_train_loss=None):
        """function that trains the model

        Args:
            data (torch.tensor): data to train the model
            max_learning_rate (float, optional): sets the max learning rate for the learning rate cycler. Defaults to 1e-4.
            coef_1 (float, optional): hyperparameter for ln loss. Defaults to 0.
            coef_2 (float, optional): hyperparameter for contrastive loss. Defaults to 0.
            coef_3 (float, optional): hyperparameter for divergency loss. Defaults to 0.
            seed (int, optional): sets the random seed. Defaults to 12.
            epochs (int, optional): number of epochs to train. Defaults to 100.
            with_scheduler (bool, optional): sets if you should use the learning rate cycler. Defaults to True.
            ln_parm (int, optional): order of the Ln regularization. Defaults to 1.
            epoch_ (int, optional): current epoch for continuing training. Defaults to None.
            folder_path (str, optional): path where to save the weights. Defaults to './'.
            batch_size (int, optional): sets the batch size for training. Defaults to 32.
            best_train_loss (float, optional): current loss value to determine if you should save the value. Defaults to None.
        """

        make_folder(folder_path)

        # set seed
        torch.manual_seed(seed)

        # builds the dataloader
        self.DataLoader_ = DataLoader(
            data.reshape(-1, 256, 256), batch_size=batch_size, shuffle=True)

        # option to use the learning rate scheduler
        if with_scheduler:
            scheduler = torch.optim.lr_scheduler.CyclicLR(
                self.optimizer, base_lr=self.learning_rate, max_lr=max_learning_rate, step_size_up=15, cycle_momentum=False)
        else:
            scheduler = None

        # set the number of epochs
        N_EPOCHS = epochs

        # initializes the best train loss
        if best_train_loss == None:
            best_train_loss = float('inf')

        # initialize the epoch counter
        if epoch_ is None:
            self.start_epoch = 0
        else:
            self.start_epoch = epoch_+1

        # training loop
        for epoch in range(self.start_epoch, N_EPOCHS):

            train = self.loss_function(
                self.DataLoader_, coef_1, coef_2, coef_3, ln_parm)
            train_loss = train
            train_loss /= len(self.DataLoader_)
            print(
                f'Epoch: {epoch:03d}/{N_EPOCHS:03d} | Train Loss: {train_loss:.4f}')
            print('.............................')

          #  schedular.step()
            if best_train_loss > train_loss:
                best_train_loss = train_loss
                checkpoint = {
                    "net": self.autoencoder.state_dict(),
                    'optimizer': self.optimizer.state_dict(),
                    "epoch": epoch,
                    "encoder": self.encoder.state_dict(),
                    'decoder': self.decoder.state_dict(),
                }
                if epoch >= 0:
                    lr_ = format(self.optimizer.param_groups[0]['lr'], '.5f')
                    file_path = folder_path + '/Weight_' +\
                        f'epoch:{epoch:04d}_l1coef:{coef_1:.4f}'+'_lr:'+lr_ +\
                        f'_trainloss:{train_loss:.4f}.pkl'
                    torch.save(checkpoint, file_path)

            if scheduler is not None:
                scheduler.step()

    def loss_function(self,
                      train_iterator,
                      coef=0,
                      coef1=0,
                      coef2=0,
                      ln_parm=1,
                      beta=None):
        """computes the loss function for the training

        Args:
            train_iterator (torch.Dataloader): dataloader for the training
            coef (float, optional): Ln hyperparameter. Defaults to 0.
            coef1 (float, optional): hyperparameter for contrastive loss. Defaults to 0.
            coef2 (float, optional): hyperparameter for divergence loss. Defaults to 0.
            ln_parm (float, optional): order of the regularization. Defaults to 1.
            beta (float, optional): beta value for VAE. Defaults to None.

        Returns:
            _type_: _description_
        """

        # set the train mode
        self.autoencoder.train()

        # loss of the epoch
        train_loss = 0
        con_l = ContrastiveLoss(coef1).to(self.device)

        for x in tqdm(train_iterator, leave=True, total=len(train_iterator)):

            x = x.to(self.device, dtype=torch.float)

            maxi_ = DivergenceLoss(x.shape[0], coef2).to(self.device)

            # update the gradients to zero
            self.optimizer.zero_grad()

            if beta is None:
                embedding = self.encoder(x)
            else:
                embedding, sd, mn = self.encoder(x)

            reg_loss_1 = coef * \
                torch.norm(embedding, ln_parm).to(self.device)/x.shape[0]

            if reg_loss_1 == 0:

                reg_loss_1 = 0.5

            predicted_x = self.decoder(embedding)

            contras_loss = con_l(embedding)
            maxi_loss = maxi_(embedding)

            # reconstruction loss
            loss = F.mse_loss(x, predicted_x, reduction='mean')

            loss = loss + reg_loss_1 + contras_loss - maxi_loss

            # backward pass
            train_loss += loss.item()
            loss.backward()
            # update the weights
            self.optimizer.step()

        return train_loss

    def load_weights(self, path_checkpoint,return_checkpoint=False):
        """loads the weights from a checkpoint

        Args:
            path_checkpoint (str): path where checkpoints are saved 
            return_checkpoint (bool, Optional): whether to return the checkpoint loaded. Default False
        
        Returns:
            checkpoint (Optional)
        """
        checkpoint = torch.load(path_checkpoint)
        self.autoencoder.load_state_dict(checkpoint['net'])
        self.encoder.load_state_dict(checkpoint['encoder'])
        self.decoder.load_state_dict(checkpoint['decoder'])
        self.optimizer.load_state_dict(checkpoint['optimizer'])
        self.start_epoch = checkpoint['epoch']
        
        if return_checkpoint: return checkpoint

    def get_embedding(self, data, batch_size=32):
        """extracts embeddings from the data

        Args:
            data (torch.tensor): data to get embeddings from
            batch_size (int, optional): batchsize for inference. Defaults to 32.

        Returns:
            torch.tensor: predicted embeddings
        """

        # builds the dataloader
        dataloader = DataLoader(
            data.reshape(-1, data.shape[2], data.shape[3]), batch_size, shuffle=False)

        embedding_ = np.zeros(
            [data.shape[0]*data.shape[1], self.embedding_size])
        for i, x in enumerate(tqdm(dataloader, leave=True, total=len(dataloader))):
            with torch.no_grad():
                value = x
                test_value = Variable(value.to(self.device))
                test_value = test_value.float()
                embedding = self.encoder(test_value).to('cpu').detach().numpy()
                embedding_[i*batch_size:(i+1)*batch_size, :] = embedding

        self.embedding = embedding_

        return embedding_

    def generate_spectra(self, embedding):
        """generates spectra from embeddings

        Args:
            embedding (torch.tensor): predicted embeddings to decode

        Returns:
            torch.tensor: decoded spectra
        """

        embedding = torch.from_numpy(np.atleast_2d(embedding)).to(self.device)
        embedding = self.decoder(embedding.float())
        embedding = embedding.cpu().detach().numpy()
        return embedding


class VariationalAutoencoder(ConvAutoencoder):
    def __init__(self,
                 encoder_step_size, pooling_list,
                 decoder_step_size, upsampling_list,
                 embedding_size, conv_size,
                 device, learning_rate=3e-5, 
                ):
        super().__init__(encoder_step_size, pooling_list,
                    decoder_step_size, upsampling_list,
                    embedding_size, conv_size,
                    device, learning_rate)
        self.train=True
        self.compile_model()
            
    def compile_model(self):
        """function that complies the neural network model
        """
        # builds the encoder
        self.encoder = Variational_Encoder(
            original_step_size=self.encoder_step_size,
            pooling_list=self.pooling_list,
            embedding_size=self.embedding_size,
            conv_size=self.conv_size,
        ).to(self.device)

        # builds the decoder
        self.decoder = Decoder(
            original_step_size=self.decoder_step_size,
            upsampling_list=self.upsampling_list,
            embedding_size=self.embedding_size,
            conv_size=self.conv_size,
            pooling_list=self.pooling_list,
        ).to(self.device)

        # builds the autoencoder
        self.autoencoder = VAE(
            self.encoder, self.decoder).to(self.device)

        # sets the optimizers
        self.optimizer = optim.Adam(
            self.autoencoder.parameters(), lr=self.learning_rate
        )

        # sets the datatype of the model to float32
        self.autoencoder.type(torch.float32)
    
    def loss_function(self,
                      train_iterator,
                      coef=0,
                      coef1=0,
                      coef2=0,
                      ln_parm=1,
                      beta=None):
        """computes the loss function for the training

        Args:
            train_iterator (torch.Dataloader): dataloader for the training
            coef (float, optional): Ln hyperparameter. Defaults to 0.
            coef1 (float, optional): hyperparameter for contrastive loss. Defaults to 0.
            coef2 (float, optional): hyperparameter for divergence loss. Defaults to 0.
            ln_parm (float, optional): order of the regularization. Defaults to 1.
            beta (float, optional): beta value for VAE. Defaults to None.

        Returns:
            _type_: _description_
        """

        # set the train mode
        self.autoencoder.train()

        # loss of the epoch
        train_loss = 0
        con_l = ContrastiveLoss(coef1).to(self.device)

        for x in tqdm(train_iterator, leave=True, total=len(train_iterator)):

            x = x.to(self.device, dtype=torch.float)

            maxi_ = DivergenceLoss(x.shape[0], coef2).to(self.device)

            # update the gradients to zero
            self.optimizer.zero_grad()
            # embedding, mean, log(variance)
            embedding,mn,sd = self.encoder(x)
            reg_loss_1 = coef * \
                torch.norm(embedding, ln_parm).to(self.device)/x.shape[0]

            if reg_loss_1 == 0:
                reg_loss_1 = 0.5

            contras_loss = con_l(embedding)
            maxi_loss = maxi_(embedding)
            kl_loss = -0.5 * torch.mean(sd - torch.square(mn) - torch.exp(sd) + 1)

            # get generated image
            predicted_x = self.decoder(embedding)
            
            # reconstruction loss
            loss = F.mse_loss(x, predicted_x, reduction='mean')

            loss = loss + reg_loss_1 + contras_loss - maxi_loss + beta*kl_loss

            # backward pass
            train_loss += loss.item()
            loss.backward()
            # update the weights
            self.optimizer.step()

        return train_loss

    def Train(self, data,
              max_learning_rate=1e-4,
              coef_1=0,
              coef_2=0,
              coef_3=0,
              beta=0,
              beta_schedule=[0,0],
              seed=12,
              epochs=100,
              with_scheduler=True,
              ln_parm=1,
              epoch_=None,
              folder_path='./',
              batch_size=32,
              best_train_loss=None):
        """function that trains the model

        Args:
            data (torch.tensor): data to train the model
            max_learning_rate (float, optional): sets the max learning rate for the learning rate cycler. Defaults to 1e-4.
            coef_1 (float, optional): hyperparameter for ln loss. Defaults to 0.
            coef_2 (float, optional): hyperparameter for contrastive loss. Defaults to 0.
            coef_3 (float, optional): hyperparameter for divergency loss. Defaults to 0.
            beta (float, optional): hyperparameter for KL-divergency loss. Defaults to 0.
            beta_schedule (list, optional): hyperparameter for changing beta. [incr_by, per_epoch]. Defaults to [0,0],
            seed (int, optional): sets the random seed. Defaults to 12.
            epochs (int, optional): number of epochs to train. Defaults to 100.
            with_scheduler (bool, optional): sets if you should use the learning rate cycler. Defaults to True.
            ln_parm (int, optional): order of the Ln regularization. Defaults to 1.
            epoch_ (int, optional): current epoch for continuing training. Defaults to None.
            folder_path (str, optional): path where to save the weights. Defaults to './'.
            batch_size (int, optional): sets the batch size for training. Defaults to 32.
            best_train_loss (float, optional): current loss value to determine if you should save the value. Defaults to None.
        """

        make_folder(folder_path)

        # set seed
        torch.manual_seed(seed)

        # builds the dataloader
        self.DataLoader_ = DataLoader(
            data.reshape(-1, 256, 256), batch_size=batch_size, shuffle=True)

        # option to use the learning rate scheduler
        if with_scheduler:
            scheduler = torch.optim.lr_scheduler.CyclicLR(
                self.optimizer, base_lr=self.learning_rate, max_lr=max_learning_rate, step_size_up=15, cycle_momentum=False)
        else:
            scheduler = None

        # set the number of epochs
        N_EPOCHS = epochs

        # initializes the best train loss
        if best_train_loss == None:
            best_train_loss = float('inf')

        # initialize the epoch counter
        if epoch_ is None: self.start_epoch = 0
        else: self.start_epoch = epoch_+1

        # training loop
        for epoch in range(self.start_epoch, N_EPOCHS):
            
            # increment beta if necessary
            if beta_schedule != [0,0]:
                if epoch%beta_schedule[1]==0: beta+=beta_schedule[0]

            train = self.loss_function(self.DataLoader_, coef_1, coef_2, coef_3, ln_parm,beta)
            train_loss = train
            train_loss /= len(self.DataLoader_)
            print(f'Epoch: {epoch:03d}/{N_EPOCHS:03d} | Train Loss: {train_loss:.4f}')
            print('.............................')

          #  schedular.step()
            # if best_train_loss > train_loss:
            #     best_train_loss = train_loss
            checkpoint = {
                "net": self.autoencoder.state_dict(),
                'optimizer': self.optimizer.state_dict(),
                "epoch": epoch,
                "encoder": self.encoder.state_dict(),
                'decoder': self.decoder.state_dict(),
                'beta': beta,
                'loss': train_loss
            }
            if epoch >= 0:
                lr_ = format(self.optimizer.param_groups[0]['lr'], '.5f')
                file_path = folder_path + '/Weight_' +\
                    f'epoch:{epoch:04d}_l1coef:{coef_1:.4f}'+'_lr:'+lr_ +\
                    f'_trainloss:{train_loss:.4f}.pkl'
                torch.save(checkpoint, file_path)

            if scheduler is not None:
                scheduler.step()

    def load_weights(self, path_checkpoint,return_checkpoint=False,embedding_h5_filepath=''):
        """loads the weights from a checkpoint

        Args:
            path_checkpoint (str): path where checkpoints are saved 
            return_checkpoint (bool, Optional): whether to return the checkpoint loaded. Default False
            embedding_h5_filepath (string, Optional): name of the embedding h5 file with checkpoints written in
        
        Returns:
            checkpoint (Optional)
        """
        checkpoint = torch.load(path_checkpoint)
        self.autoencoder.load_state_dict(checkpoint['net'])
        self.encoder.load_state_dict(checkpoint['encoder'])
        self.decoder.load_state_dict(checkpoint['decoder'])
        self.optimizer.load_state_dict(checkpoint['optimizer'])
        self.start_epoch = checkpoint['epoch']
        self.beta = checkpoint['beta']
        self.checkpoint_name = path_checkpoint.split('/')[-1].split('.pkl')[0]
        
        if len(embedding_h5_filepath)>0:
            try:
                with h5py.File(embedding_h5_filepath) as h:
                    self.embedding = h[self.checkpoint_name][:]
            except Exception as error: 
                print(error)
                print('Embedding not set')
        
        if return_checkpoint: return checkpoint

    def get_embedding(self, data, batch_size=32, embedding_=None):
        """extracts embeddings from the data

        Args:
            data (torch.tensor): data to get embeddings from
            batch_size (int, optional): batchsize for inference. Defaults to 32.
            embedding_ (h5 dataset, optional): dataset_to write to h5 file. Defaults to None

        Returns:
            torch.tensor: predicted embeddings
        """

        # builds the dataloader
        dataloader = DataLoader(
            data.reshape(-1, data.shape[2], data.shape[3]), batch_size, 
            shuffle=False)

        if embedding_==None:
            embedding_ = np.zeros(
                [data.shape[0]*data.shape[1], self.embedding_size])
            
        for i, x in enumerate(tqdm(dataloader, leave=True, total=len(dataloader))):
            with torch.no_grad():
                value = x
                test_value = Variable(value.to(self.device))
                test_value = test_value.float()
                embedding,mn,sd = self.encoder(test_value)
                embedding_[i*batch_size:(i+1)*batch_size, :] = embedding.to('cpu').detach().numpy()

        self.embedding = embedding_[:]

        return embedding_
    
    def write_multi_embeddings(self,input_folder,output_folder,input_data,
                               output_filename='embeddings.h5',batch_size=32,overwrite=False):
        
        checkpoint_pathlist = glob.glob(f'{input_folder}/*.pkl')
        checkpoint_pathlist.sort()
        
        try: h = h5py.File(f'{output_folder}/{output_filename}','r+')
        except: h = h5py.File(f'{output_folder}/{output_filename}','w')
        h.close()
        
        with h5py.File(f'{output_folder}/{output_filename}','r+') as h:
            
            for checkpoint_path in checkpoint_pathlist:
                check_name = checkpoint_path.split('/')[-1].split('.pkl')[0]
                print(check_name)
                if check_name in h and not overwrite: 
                    print('Skipped\n')
                    continue # skip names already written
                
                checkpoint = self.load_weights(checkpoint_path, return_checkpoint=True)
                
                try:
                    embedding_dataset = h.create_dataset(check_name,shape=(input_data.shape[0]*input_data.shape[1], 
                                                            self.embedding_size))
                except:
                    embedding_dataset = h[check_name]
                
                embedding_dataset.attrs['epoch'] = checkpoint['epoch']
                embedding_dataset.attrs['beta'] = checkpoint['beta']
                
                embedding_ = self.get_embedding(input_data, embedding_=embedding_dataset)
                
    
class ConvBlock(nn.Module):
    """Convolutional Block with 3 convolutional layers, 1 layer normalization layer with ReLU and ResNet

    Args:
        nn (nn.Module): Torch module class
    """

    def __init__(self, t_size, n_step):
        """Initializes the convolutional block

        Args:
            t_size (int): Size of the convolution kernel
            n_step (int): Input shape of normalization layer
        """

        super(ConvBlock, self).__init__()
        self.cov1d_1 = nn.Conv2d(
            t_size, t_size, 3, stride=1, padding=1, padding_mode="zeros"
        )
        self.cov1d_2 = nn.Conv2d(
            t_size, t_size, 3, stride=1, padding=1, padding_mode="zeros"
        )
        self.cov1d_3 = nn.Conv2d(
            t_size, t_size, 3, stride=1, padding=1, padding_mode="zeros"
        )
        self.norm_3 = nn.LayerNorm(n_step)
        self.relu_4 = nn.ReLU()

    def forward(self, x):
        """Forward pass of the convolutional block

        Args:
            x (Tensor): Input tensor

        Returns:
            Tensor: output tensor
        """

        x_input = x
        out = self.cov1d_1(x)
        out = self.cov1d_2(out)
        out = self.cov1d_3(out)
        out = self.norm_3(out)
        out = self.relu_4(out)
        out = out.add(x_input)

        return out


class IdentityBlock(nn.Module):

    """Identity Block with 1 convolutional layers, 1 layer normalization layer with ReLU"""

    def __init__(self, t_size, n_step):
        """Initializes the identity block

        Args:
            t_size (int): Size of the convolution kernel
            n_step (int): Input shape of normalization layer
        """

        super(IdentityBlock, self).__init__()
        self.cov1d_1 = nn.Conv2d(
            t_size, t_size, 3, stride=1, padding=1, padding_mode="zeros"
        )
        self.norm_1 = nn.LayerNorm(n_step)
        self.relu = nn.ReLU()

    def forward(self, x):
        """Forward pass of the identity block

        Args:
            x (Tensor): Input tensor

        Returns:
            Tensor: output tensor
        """

        x_input = x
        out = self.cov1d_1(x)
        out = self.norm_1(out)
        out = self.relu(out)

        return out


class Encoder(nn.Module):
    """Encoder block

    Args:
        nn (nn.Module): Torch module class
    """

    def __init__(self, original_step_size, pooling_list, embedding_size, conv_size):
        """Build the encoder

        Args:
            original_step_size (Int): the x and y size of input image
            pooling_list (List): the list of parameter for each 2D MaxPool layer
            embedding_size (Int): the value for number of channels
            conv_size (Int): the value of filters number goes to each block
        """

        super(Encoder, self).__init__()

        blocks = []

        self.input_size_0 = original_step_size[0]
        self.input_size_1 = original_step_size[1]

        number_of_blocks = len(pooling_list)

        blocks.append(ConvBlock(t_size=conv_size,
                                n_step=original_step_size))
        blocks.append(IdentityBlock(
            t_size=conv_size, n_step=original_step_size))
        blocks.append(nn.MaxPool2d(
            pooling_list[0], stride=pooling_list[0]))

        for i in range(1, number_of_blocks):
            original_step_size = [
                original_step_size[0] // pooling_list[i - 1],
                original_step_size[1] // pooling_list[i - 1],
            ]
            blocks.append(ConvBlock(t_size=conv_size,
                                    n_step=original_step_size))
            blocks.append(
                IdentityBlock(t_size=conv_size, n_step=original_step_size)
            )
            blocks.append(nn.MaxPool2d(
                pooling_list[i], stride=pooling_list[i]))

        self.block_layer = nn.ModuleList(blocks)
        self.layers = len(blocks)

        original_step_size = [
            original_step_size[0] // pooling_list[-1],
            original_step_size[1] // pooling_list[-1],
        ]
        input_size = original_step_size[0] * original_step_size[1]

        self.cov2d = nn.Conv2d(
            1, conv_size, 3, stride=1, padding=1, padding_mode="zeros"
        )
        self.cov2d_1 = nn.Conv2d(
            conv_size, 1, 3, stride=1, padding=1, padding_mode="zeros"
        )

        self.relu_1 = nn.ReLU()

        self.dense = nn.Linear(input_size, embedding_size)

    def forward(self, x):
        """Forward pass of the encoder

        Args:
            x (Tensor): Input tensor

        Returns:
            Tensor: output tensor
        """
        out = x.view(-1, 1, self.input_size_0, self.input_size_1)
        out = self.cov2d(out)
        for i in range(self.layers):
            out = self.block_layer[i](out)
        out = self.cov2d_1(out)
        out = torch.flatten(out, start_dim=1)
        out = self.dense(out)
        selection = self.relu_1(out)
        # mu = self.set_mean(selection)
        # std = self.set_std(selection)
        
        # embedding_out = generate_distribution(mu,std)

        return selection


class Variational_Encoder(Encoder):
    """Variational Encoder block

    Args:
        nn (nn.Module): Torch module class
    """

    def __init__(self, original_step_size, pooling_list, embedding_size, conv_size):
        """Build the encoder

        Args:
            original_step_size (Int): the x and y size of input image
            pooling_list (List): the list of parameter for each 2D MaxPool layer
            embedding_size (Int): the value for number of channels
            conv_size (Int): the value of filters number goes to each block
        """

        super(Variational_Encoder,self).__init__(original_step_size, pooling_list, embedding_size, conv_size)
        self.set_mean = nn.Linear(embedding_size,embedding_size)
        self.set_std = nn.Linear(embedding_size,embedding_size)
             
    def generate_distribution(self,mu,var):
        """Samples a normal distribution using the given mean and variance.

        Args:
            mu (Tensor): Mean values in shape (batch_size, embedding_size)
            var (Tensor): Variance values in shape (batch_size, embedding_size)

        Returns:
            Tensor: Sampled values in shape (batch_size, embedding_size)
        """        
        z_mean = torch.clone(mu)
        z_log_var = torch.clone(var)
        batch = z_mean.shape[0]
        dim = z_mean.shape[1]
        epsilon = torch.normal(0,1,(batch,dim),device=mu.device)
        return z_mean + torch.exp(0.5 * z_log_var) * epsilon  

    def forward(self, x):
        """Forward pass of the encoder

        Args:
            x (Tensor): Input tensor

        Returns:
            embedding_out (Tensor): sampled embedding
            mu (Tensor): mean
            std (Tensor): log of the variance
        """
        out = x.view(-1, 1, self.input_size_0, self.input_size_1)
        out = self.cov2d(out)
        for i in range(self.layers):
            out = self.block_layer[i](out)
        out = self.cov2d_1(out)
        out = torch.flatten(out, start_dim=1)
        out = self.dense(out)
        selection = self.relu_1(out)
        
        mu = self.set_mean(selection)
        std = self.set_std(selection)
        embedding_out = self.generate_distribution(mu,std)

        return embedding_out, mu, std


class Decoder(nn.Module):
    """Decoder class

    Args:
        nn (nn.module): base class for all neural network modules
    """

    def __init__(
        self,
        original_step_size,
        upsampling_list,
        embedding_size,
        conv_size,
        pooling_list,
    ):
        """Decoder block

        Args:
            original_step_size (Int): the x and y size of input image
            upsampling_list (Int): the list of parameter for each 2D upsample layer
            embedding_size (Int): the value for number of channels
            conv_size (Int): the value of filters number goes to each block
            pooling_list (List): the list of parameter for each 2D MaxPool layer
        """

        super(Decoder, self).__init__()
        self.input_size_0 = original_step_size[0]
        self.input_size_1 = original_step_size[1]
        self.dense = nn.Linear(
            embedding_size, original_step_size[0] * original_step_size[1]
        )
        self.cov2d = nn.Conv2d(
            1, conv_size, 3, stride=1, padding=1, padding_mode="zeros"
        )
        self.cov2d_1 = nn.Conv2d(
            conv_size, 1, 3, stride=1, padding=1, padding_mode="zeros"
        )

        blocks = []
        number_of_blocks = len(pooling_list)
        blocks.append(ConvBlock(t_size=conv_size,
                                n_step=original_step_size))
        blocks.append(IdentityBlock(
            t_size=conv_size, n_step=original_step_size))
        for i in range(number_of_blocks):
            blocks.append(
                nn.Upsample(
                    scale_factor=upsampling_list[i],
                    mode="bilinear",
                    align_corners=True,
                )
            )
            original_step_size = [
                original_step_size[0] * upsampling_list[i],
                original_step_size[1] * upsampling_list[i],
            ]
            blocks.append(ConvBlock(t_size=conv_size,
                                    n_step=original_step_size))
            blocks.append(
                IdentityBlock(t_size=conv_size, n_step=original_step_size)
            )

        self.block_layer = nn.ModuleList(blocks)
        self.layers = len(blocks)

        self.output_size_0 = original_step_size[0]
        self.output_size_1 = original_step_size[1]

    def forward(self, x):
        """Forward pass of the identity block

        Args:
            x (Tensor): Input tensor

        Returns:
            Tensor: output tensor
        """

        out = self.dense(x)
        out = out.view(-1, 1, self.input_size_0, self.input_size_1)

        out = self.cov2d(out)
        for i in range(self.layers):
            out = self.block_layer[i](out)
        out = self.cov2d_1(out)
        output = out.view(-1, self.output_size_0, self.output_size_1)

        return output


class AutoEncoder(nn.Module):
    def __init__(self, enc, dec):
        """AutoEncoder model

        Args:
            enc (nn.Module): Encoder block
            dec (nn.Module): Decoder block
        """
        super().__init__()

        self.enc = enc
        self.dec = dec

    def forward(self, x):
        """Forward pass of the autoencoder

        Args:
            x (Tensor): Input tensor

        Returns:
            Tensor: output tensor
        """
        
        embedding = self.enc(x)
        predicted = self.dec(embedding)

        return predicted
    
    
class VAE(nn.Module):
    def __init__(self, enc, dec):
        """
         enc: encoder part
         dec: decoder part
         
        """
        super().__init__()

        self.enc = enc
        self.dec = dec

    def forward(self, x):
        embedding,mu,std= self.enc(x)

        predicted = self.dec(embedding)
        
        return predicted