{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-22 05:34:24.258736: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-22 05:34:24.802386: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ferroelectric/micromamba/envs/paper/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2024-06-22 05:34:24.802437: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ferroelectric/micromamba/envs/paper/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2024-06-22 05:34:24.802442: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from m3_learning.be.filters import clean_interpolate\n",
    "import numpy as np\n",
    "import pytest\n",
    "from scipy.interpolate import CubicSpline\n",
    "import sys\n",
    "sys.path.append('/home/ferroelectric/Documents/m3_learning/m3_learning/src')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         2.         7.         4.        ]\n",
      " [5.         4.66666667 7.         8.        ]\n",
      " [5.         6.         7.         8.        ]\n",
      " [5.         6.         7.         8.        ]]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m expected1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[1;32m      4\u001b[0m     [[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m], [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m4.66666667\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m8\u001b[39m], [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m8\u001b[39m], [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m8\u001b[39m]])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(clean_interpolate(arr1, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(clean_interpolate(arr1, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), expected1)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "arr1 = np.array([[1, 2, np.nan, 4], [5, np.nan, 7, 8],\n",
    "                [5, 6, 7, 8], [5, 6, 7, 8]])\n",
    "expected1 = np.array(\n",
    "    [[1, 2, 3, 4], [5, 4.66666667, 7, 8], [5, 6, 7, 8], [5, 6, 7, 8]])\n",
    "\n",
    "print(clean_interpolate(arr1, axis=0))\n",
    "assert np.allclose(clean_interpolate(arr1, axis=0), expected1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.,  2., nan,  4.],\n",
       "        [ 5., nan,  7.,  8.]],\n",
       "\n",
       "       [[ 9., 10., nan, 12.],\n",
       "        [13., nan, 15., 16.]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr9 = np.array([[[1, 2, np.nan, 4], [5, np.nan, 7, 8]], [\n",
    "                    [9, 10, np.nan, 12], [13, np.nan, 15, 16]]])\n",
    "expected9 = np.array([[[1, 2, 3, 4], [5, 6, 7, 8]], [\n",
    "                        [9, 10, 11, 12], [13, 14, 15, 16]]])\n",
    "clean_interpolate(arr9, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "# sys.path.append(\"/home/ferroelectric/Documents/m3_learning/m3_learning/src\")\n",
    "sys.path.append('../../src')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from m3_learning.be.dataset import BE_Dataset\n",
    "from m3_learning.viz.printing import printer\n",
    "from m3_learning.be.nn import SHO_fit_func_nn, SHO_Model\n",
    "from m3_learning.util.file_IO import download_and_unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 556800 into shape (25,256,22272)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/ferroelectric/Documents/m3_learning/m3_learning/src/m3_learning/tests/be/BEPS_small.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# instantiate the dataset object\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mBE_Dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# print the contents of the file\u001b[39;00m\n\u001b[1;32m      7\u001b[0m dataset\u001b[38;5;241m.\u001b[39mprint_be_tree()\n",
      "File \u001b[0;32m<string>:21\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, file, scaled, raw_format, fitter, output_shape, measurement_state, resampled, LSQF_phase_shift, NN_phase_shift, verbose, noise_state, cleaned, basegroup, SHO_fit_func_LSQF, hysteresis_function, loop_interpolated, kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/Documents/m3_learning/m3_learning/src/m3_learning/tests/../../m3_learning/be/dataset.py:152\u001b[0m, in \u001b[0;36mBE_Dataset.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;66;03m# Preprocessing and raw data\u001b[39;00m\n\u001b[0;32m--> 152\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_preprocessing\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_raw_data()\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSHO_preprocessing()\n",
      "File \u001b[0;32m~/Documents/m3_learning/m3_learning/src/m3_learning/tests/../../m3_learning/be/dataset.py:238\u001b[0m, in \u001b[0;36mBE_Dataset.set_preprocessing\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m# does preprocessing for the SHO_fit results\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m in_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*SHO_Fit*\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 238\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSHO_preprocessing\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;167;01mWarning\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo SHO fit found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/m3_learning/m3_learning/src/m3_learning/tests/../../m3_learning/be/dataset.py:295\u001b[0m, in \u001b[0;36mBE_Dataset.SHO_preprocessing\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03mSHO_preprocessing conducts the preprocessing on the SHO fit results\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# extract the raw data and reshapes is\u001b[39;00m\n\u001b[0;32m--> 295\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_raw_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;66;03m# resamples the data if necessary\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_raw_data_resampler()\n",
      "File \u001b[0;32m~/Documents/m3_learning/m3_learning/src/m3_learning/tests/../../m3_learning/be/dataset.py:50\u001b[0m, in \u001b[0;36mstatic_state_decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m current_state \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_state\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# runs the function\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# resets the state\u001b[39;00m\n\u001b[1;32m     53\u001b[0m args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_attributes(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcurrent_state)\n",
      "File \u001b[0;32m~/Documents/m3_learning/m3_learning/src/m3_learning/tests/../../m3_learning/be/dataset.py:825\u001b[0m, in \u001b[0;36mBE_Dataset.set_raw_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# loops around all the datasets and stores them reshaped in a dictionary\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_data_reshaped[dataset\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39msplit(\n\u001b[0;32m--> 825\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_pix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvoltage_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_bins\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_datasets\u001b[38;5;241m.\u001b[39mextend([dataset\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 556800 into shape (25,256,22272)"
     ]
    }
   ],
   "source": [
    "data_path = \"/home/ferroelectric/Documents/m3_learning/m3_learning/src/m3_learning/tests/be/BEPS_small.h5\"\n",
    "\n",
    "# instantiate the dataset object\n",
    "dataset = BE_Dataset(data_path)\n",
    "\n",
    "# print the contents of the file\n",
    "dataset.print_be_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdataset\u001b[49m\u001b[38;5;241m.\u001b[39mnum_pix\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "dataset.num_pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ferroelectric/micromamba/envs/paper/lib/python3.10/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    div#notebook-container    { width: 95%; }\n",
       "    div#menubar-container     { width: 65%; }\n",
       "    div#maintoolbar-container { width: 99%; }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ensure python 3 compatibility\n",
    "from __future__ import division, print_function, absolute_import\n",
    "import sidpy\n",
    "import pyUSID as usid\n",
    "from BGlib import be as belib\n",
    "\n",
    "# Import necessary libraries:\n",
    "# General utilities:\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "\n",
    "# Computation:\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "# Visualization:\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Finally, BGlib itself\n",
    "sys.path.append('..')\n",
    "\n",
    "\n",
    "# Make Notebook take up most of page width\n",
    "display(HTML(data=\"\"\"\n",
    "<style>\n",
    "    div#notebook-container    { width: 95%; }\n",
    "    div#menubar-container     { width: 65%; }\n",
    "    div#maintoolbar-container { width: 99%; }\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File is already Pycroscopy ready.\n",
      "Working on:\n",
      "/home/ferroelectric/Documents/m3_learning/m3_learning/src/m3_learning/tests/be/BEPS_small.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ferroelectric/micromamba/envs/paper/lib/python3.10/site-packages/sidpy/sid/translator.py:42: FutureWarning: Consider using sidpy.Reader instead of sidpy.Translator if possible and contribute your reader to ScopeReaders\n",
      "  warn('Consider using sidpy.Reader instead of sidpy.Translator if '\n"
     ]
    }
   ],
   "source": [
    "input_file_path = \"/home/ferroelectric/Documents/m3_learning/m3_learning/src/m3_learning/tests/be/BEPS_small.h5\"\n",
    "\n",
    "(data_dir, filename) = os.path.split(input_file_path)\n",
    "\n",
    "if input_file_path.endswith('.h5'):\n",
    "    # No translation here\n",
    "    h5_path = input_file_path\n",
    "    force = False  # Set this to true to force patching of the datafile.\n",
    "    tl = belib.translators.LabViewH5Patcher()\n",
    "    tl.translate(h5_path, force_patch=force)\n",
    "else:\n",
    "    # Set the data to be translated\n",
    "    data_path = input_file_path\n",
    "\n",
    "    (junk, base_name) = os.path.split(data_dir)\n",
    "\n",
    "    # Check if the data is in the new or old format.  Initialize the correct translator for the format.\n",
    "    if base_name == 'newdataformat':\n",
    "        (junk, base_name) = os.path.split(junk)\n",
    "        translator = belib.translators.BEPSndfTranslator(max_mem_mb=max_mem)\n",
    "    else:\n",
    "        translator = belib.translators.BEodfTranslator(max_mem_mb=max_mem)\n",
    "    if base_name.endswith('_d'):\n",
    "        base_name = base_name[:-2]\n",
    "    # Translate the data\n",
    "    h5_path = translator.translate(\n",
    "        data_path, show_plots=True, save_plots=False)\n",
    "\n",
    "h5_file = h5py.File(h5_path, 'r+')\n",
    "print('Working on:\\n' + h5_path)\n",
    "\n",
    "h5_main = usid.hdf_utils.find_dataset(h5_file, 'Raw_Data')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets and datagroups within the file:\n",
      "------------------------------------\n",
      "/\n",
      "├ Measurement_000\n",
      "  ---------------\n",
      "  ├ Channel_000\n",
      "    -----------\n",
      "    ├ Bin_FFT\n",
      "    ├ Bin_Frequencies\n",
      "    ├ Bin_Indices\n",
      "    ├ Bin_Step\n",
      "    ├ Bin_Wfm_Type\n",
      "    ├ Excitation_Waveform\n",
      "    ├ Noise_Floor\n",
      "    ├ Position_Indices\n",
      "    ├ Position_Values\n",
      "    ├ Raw_Data\n",
      "    ├ Raw_Data-SHO_Fit_000\n",
      "      --------------------\n",
      "      ├ Fit\n",
      "      ├ Guess\n",
      "      ├ Spectroscopic_Indices\n",
      "      ├ Spectroscopic_Values\n",
      "    ├ Spatially_Averaged_Plot_Group_000\n",
      "      ---------------------------------\n",
      "      ├ Bin_Frequencies\n",
      "      ├ Mean_Spectrogram\n",
      "      ├ Spectroscopic_Parameter\n",
      "      ├ Step_Averaged_Response\n",
      "    ├ Spatially_Averaged_Plot_Group_001\n",
      "      ---------------------------------\n",
      "      ├ Bin_Frequencies\n",
      "      ├ Mean_Spectrogram\n",
      "      ├ Spectroscopic_Parameter\n",
      "      ├ Step_Averaged_Response\n",
      "    ├ Spectroscopic_Indices\n",
      "    ├ Spectroscopic_Values\n",
      "    ├ UDVS\n",
      "    ├ UDVS_Indices\n",
      "\n",
      "The main dataset:\n",
      "------------------------------------\n",
      "<HDF5 dataset \"Raw_Data\": shape (25, 22272), type \"<c8\">\n",
      "\n",
      "The ancillary datasets:\n",
      "------------------------------------\n",
      "<HDF5 dataset \"Position_Indices\": shape (25, 2), type \"<u4\">\n",
      "<HDF5 dataset \"Position_Values\": shape (25, 2), type \"<f4\">\n",
      "<HDF5 dataset \"Spectroscopic_Indices\": shape (4, 22272), type \"<i4\">\n",
      "<HDF5 dataset \"Spectroscopic_Values\": shape (4, 22272), type \"<f4\">\n",
      "\n",
      "Metadata or attributes in a datagroup\n",
      "------------------------------------\n",
      "BE_actual_duration_[s] : 0.004\n",
      "BE_amplitude_[V] : 1.5\n",
      "BE_auto_smoothing : b'auto smoothing on'\n",
      "BE_band_edge_smoothing_[s] : 2560.5\n",
      "BE_band_edge_trim : 0.14614\n",
      "BE_band_width_[Hz] : 60000\n",
      "BE_bins_per_band : 0\n",
      "BE_center_frequency_[Hz] : 385000\n",
      "BE_desired_duration_[s] : 0.004\n",
      "BE_phase_content : b'chirp-sinc hybrid'\n",
      "BE_phase_variation : 1\n",
      "BE_points_per_BE_wave : 0\n",
      "BE_repeats : 2\n",
      "FORC_V_high1_[V] : 1\n",
      "FORC_V_high2_[V] : 10\n",
      "FORC_V_low1_[V] : -1\n",
      "FORC_V_low2_[V] : -10\n",
      "FORC_num_of_FORC_cycles : 1\n",
      "FORC_num_of_FORC_repeats : 1\n",
      "File_MDAQ_version : b'MDAQ_VS_111114_01'\n",
      "File_date_and_time : b'26-Feb-2015 14:49:48'\n",
      "File_file_name : b'in_out_BEPS_5x5'\n",
      "File_file_path : b'V:\\\\Users\\\\Sangmo\\\\KTaO3\\\\150226\\\\onSTO650\\\\'\n",
      "File_file_suffix : 3\n",
      "IO_AO_amplifier : 1\n",
      "IO_AO_range_[V] : b'+/- 10'\n",
      "IO_Analog_Input_1 : b'+/- .1V, FFT'\n",
      "IO_Analog_Input_2 : b'off'\n",
      "IO_Analog_Input_3 : b'off'\n",
      "IO_Analog_Input_4 : b'off'\n",
      "IO_DAQ_platform : b'NI 6115'\n",
      "IO_rate_[Hz] : 2000000\n",
      "VS_amplitude_[V] : 8\n",
      "VS_cycle_fraction : b'full'\n",
      "VS_cycle_phase_shift : 0\n",
      "VS_measure_in_field_loops : b'in and out-of-field'\n",
      "VS_mode : b'DC modulation mode'\n",
      "VS_number_of_cycles : 2\n",
      "VS_offset_[V] : 0\n",
      "VS_read_voltage_[V] : 0\n",
      "VS_set_pulse_amplitude[V] : 0\n",
      "VS_set_pulse_duration[s] : 0.002\n",
      "VS_step_edge_smoothing_[s] : 0.001\n",
      "VS_steps_per_full_cycle : 64\n",
      "data_type : b'BEPSData'\n",
      "grid_/single : b'grid'\n",
      "grid_contact_set_point_[V] : 0.75\n",
      "grid_current_col : 1\n",
      "grid_current_row : 1\n",
      "grid_cycle_time_[s] : 10\n",
      "grid_measuring : 0\n",
      "grid_moving : 0\n",
      "grid_num_cols : 5\n",
      "grid_num_rows : 5\n",
      "grid_settle_time_[s] : 0.05\n",
      "grid_time_remaining_[h;m;s] : 10\n",
      "grid_total_time_[h;m;s] : 10\n",
      "grid_transit_set_point_[V] : 0\n",
      "grid_transit_time_[s] : 0.1\n",
      "num_bins : 22272\n",
      "num_pix : 25\n",
      "num_udvs_steps : 256\n"
     ]
    }
   ],
   "source": [
    "print('Datasets and datagroups within the file:\\n------------------------------------')\n",
    "usid.hdf_utils.print_tree(h5_file)\n",
    "\n",
    "print('\\nThe main dataset:\\n------------------------------------')\n",
    "print(h5_main)\n",
    "print('\\nThe ancillary datasets:\\n------------------------------------')\n",
    "print(h5_file['/Measurement_000/Channel_000/Position_Indices'])\n",
    "print(h5_file['/Measurement_000/Channel_000/Position_Values'])\n",
    "print(h5_file['/Measurement_000/Channel_000/Spectroscopic_Indices'])\n",
    "print(h5_file['/Measurement_000/Channel_000/Spectroscopic_Values'])\n",
    "\n",
    "print('\\nMetadata or attributes in a datagroup\\n------------------------------------')\n",
    "for key in h5_file['/Measurement_000'].attrs:\n",
    "    print('{} : {}'.format(key, h5_file['/Measurement_000'].attrs[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
